{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fef01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from types import SimpleNamespace\n",
    "from typing import Optional, Tuple, Dict\n",
    "import os, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import time\n",
    "import math\n",
    "import itertools\n",
    "import ellipse_mean_stable as em\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4cbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Here we test for different values of:\n",
    "    tau schedule (constant, increasing , decreasing)  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2adb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "def set_seed(seed: int, device: str):\n",
    "    torch.manual_seed(seed)\n",
    "    if device.startswith(\"cuda\"):\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def make_spd_cov(d: int, device: str, dtype: torch.dtype, seed: int = 0):\n",
    "    \"\"\"Random SPD covariance with moderate conditioning.\"\"\"\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "    B = torch.randn(d,d, generator=g, device=device, dtype=dtype)\n",
    "    Sigma = (B @ B.T) / d + 0.2 * torch.eye(d, device=device, dtype=dtype)\n",
    "    return Sigma\n",
    "\n",
    "\n",
    "def maha_error(mu_hat: torch.Tensor, mu_true: torch.Tensor, Sigma_true: torch.Tensor) -> float:\n",
    "    \"\"\"Mahalanobis norm ||mu_hat - mu||_{Sigma^{-1}}.\"\"\"\n",
    "    delta = (mu_hat - mu_true).to(Sigma_true.device, Sigma_true.dtype)\n",
    "    Sinv = torch.linalg.inv(Sigma_true)\n",
    "    val = delta @ Sinv @ delta\n",
    "    return float(torch.sqrt(torch.clamp(val, min=0.0)).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def sample_gaussian(n, d, mu_true, Sigma_true, device, dtype, seed):\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "    L = torch.linalg.cholesky(Sigma_true)\n",
    "    Z = torch.randn(n, d, generator=g, device=device, dtype=dtype)\n",
    "    return mu_true.unsqueeze(0) + Z @ L.T\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_skewed(n, d, mu_true, Sigma_true, skew_dir, skew_scale,\n",
    "                  device, dtype, seed):\n",
    "    \"\"\"\n",
    "    skew_dir   : (d,) direction of skew (unit vector recommended)\n",
    "    skew_scale : scalar controlling skew strength\n",
    "    \"\"\"\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    L = torch.linalg.cholesky(Sigma_true)\n",
    "    Z = torch.randn(n, d, generator=g, device=device, dtype=dtype)\n",
    "\n",
    "    # Latent skew variable\n",
    "    U = torch.randn(n, 1, generator=g, device=device, dtype=dtype)\n",
    "    skew = skew_scale * torch.relu(U) * skew_dir.view(1, -1)\n",
    "\n",
    "    X = Z @ L.T + skew\n",
    "    return mu_true.unsqueeze(0) + X\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_contaminated_gaussian(n, d, mu_true, Sigma_true, device, dtype, seed,\n",
    "                                eta=0.1, shift_scale=8.0, inflate=3.0):\n",
    "    \"\"\"\n",
    "    Huber contamination: (1-eta) N(mu, Sigma) + eta N(mu + shift, inflate*Sigma).\n",
    "    shift direction is random but fixed per seed.\n",
    "    \"\"\"\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    # clean\n",
    "    L = torch.linalg.cholesky(Sigma_true)\n",
    "    Z = torch.randn(n, d, generator=g, device=device, dtype=dtype)\n",
    "    X_clean = mu_true.unsqueeze(0) + Z @ L.T\n",
    "\n",
    "    # contam mask\n",
    "    mask = (torch.rand(n, generator=g, device=device) < eta)\n",
    "    m = int(mask.sum().item())\n",
    "    if m == 0:\n",
    "        return X_clean\n",
    "\n",
    "    # contamination distribution\n",
    "    # random shift direction\n",
    "    v = torch.randn(d, generator=g, device=device, dtype=dtype)\n",
    "    v = v / torch.linalg.norm(v).clamp_min(1e-12)\n",
    "    shift = shift_scale * v  # magnitude\n",
    "\n",
    "    Sigma_cont = inflate * Sigma_true\n",
    "    Lc = torch.linalg.cholesky(Sigma_cont)\n",
    "    Zc = torch.randn(m, d, generator=g, device=device, dtype=dtype)\n",
    "    X_cont = (mu_true + shift).unsqueeze(0) + Zc @ Lc.T\n",
    "\n",
    "    X = X_clean.clone()\n",
    "    X[mask] = X_cont\n",
    "    return X\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_banana(n, d, mu_true, Sigma_true,\n",
    "                  device, dtype, seed, b=0.2):\n",
    "    \"\"\"\n",
    "    Banana-shaped distribution:\n",
    "      Start with Y ~ N(0, Sigma_true), then warp:\n",
    "        X1 = Y1\n",
    "        X2 = Y2 + b*(Y1^2 - E[Y1^2])\n",
    "      and keep remaining coords as-is.\n",
    "    This is strongly non-elliptical (curved level sets).\n",
    "    \"\"\"\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    L = torch.linalg.cholesky(Sigma_true)\n",
    "    Y = torch.randn(n, d, generator=g, device=device, dtype=dtype) @ L.T\n",
    "\n",
    "    # Warp in first two coordinates\n",
    "    y1 = Y[:, 0]\n",
    "    y2 = Y[:, 1]\n",
    "    # Center the quadratic term so mean stays controlled\n",
    "    y1_var = torch.var(y1, unbiased=False)\n",
    "    Y[:, 1] = y2 + b * (y1**2 - y1_var)\n",
    "\n",
    "    return mu_true.view(1, d) + Y\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample_multivariate_t(n, d, mu_true, Sigma_true, device, dtype, seed, df=3.0):\n",
    "    \"\"\"\n",
    "    Multivariate t via scale-mixture:\n",
    "      X = mu + Z / sqrt(U/df),  Z ~ N(0,Sigma), U ~ ChiSquare(df)\n",
    "    \"\"\"\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    L = torch.linalg.cholesky(Sigma_true)\n",
    "    Z = torch.randn(n, d, generator=g, device=device, dtype=dtype) @ L.T  # N(0,Sigma)\n",
    "\n",
    "    # Chi-square(df) can be sampled via Gamma(k=df/2, theta=2)\n",
    "    # U ~ Gamma(df/2, 2)\n",
    "    U = torch.distributions.Gamma(concentration=df/2.0, rate=0.5).sample((n,)).to(device=device, dtype=dtype)\n",
    "    scale = torch.sqrt(U / df).clamp_min(1e-12)  # (n,)\n",
    "\n",
    "    X = mu_true.unsqueeze(0) + Z / scale.unsqueeze(1)\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6247bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_skew_dir(d, device, dtype, seed):\n",
    "    g = torch.Generator(device=device)\n",
    "    g.manual_seed(seed)\n",
    "    v = torch.randn(d, generator=g, device=device, dtype=dtype)\n",
    "    return v / torch.norm(v)\n",
    "\n",
    "def _setting_seed(seed0, rep, n, d, rho, *, dist, R_max=None, beta=None, tau=None, iters=None):\n",
    "    # Stable integer tags for floats\n",
    "    rho_tag  = int(round(1e6 * float(rho)))\n",
    "    R_tag    = 0 if R_max is None else int(round(1e6 * float(R_max)))\n",
    "    beta_tag = 0 if beta  is None else int(round(1e6 * float(beta)))\n",
    "    tau_tag  = 0 if tau   is None else int(round(1e6 * float(tau)))\n",
    "    it_tag   = 0 if iters is None else int(iters)\n",
    "\n",
    "    # Dist tag (stable across runs)\n",
    "    dist_tag = sum((i + 1) * ord(c) for i, c in enumerate(str(dist))) % 1_000_000\n",
    "\n",
    "    # Mix everything into a 32-bit-ish seed\n",
    "    seed = (\n",
    "        int(seed0)\n",
    "        + 1_000_000 * int(rep)\n",
    "        + 10_000 * int(d)\n",
    "        + 97 * int(n)\n",
    "        + 31 * int(rho_tag)\n",
    "        + 17 * int(dist_tag)\n",
    "        + 13 * int(R_tag)\n",
    "        + 11 * int(beta_tag)\n",
    "        + 7  * int(tau_tag)\n",
    "        + 5  * int(it_tag)\n",
    "    )\n",
    "    return int(seed % 2_147_483_647)  # keep it in a safe int range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643221e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _device():\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_data(dist, n, d, device, dtype, seed,\n",
    "                  eta=0.1, shift_scale=8.0, inflate=3.0,\n",
    "                  skew_scale=1.0):\n",
    "    mu_true = torch.ones(d, device=device, dtype=dtype)\n",
    "    Sigma_true = make_spd_cov(d, device=device, dtype=dtype, seed=seed + 17)\n",
    "\n",
    "    if dist == \"gaussian\":\n",
    "        X = sample_gaussian(n, d, mu_true, Sigma_true, device, dtype, seed)\n",
    "\n",
    "    elif dist == \"contam_gaussian\":\n",
    "        X = sample_contaminated_gaussian(\n",
    "            n, d, mu_true, Sigma_true,\n",
    "            device, dtype, seed,\n",
    "            eta=eta, shift_scale=shift_scale, inflate=inflate\n",
    "        )\n",
    "\n",
    "    elif dist == \"t3\":\n",
    "        X = sample_multivariate_t(\n",
    "            n, d, mu_true, Sigma_true,\n",
    "            device, dtype, seed, df=3.0\n",
    "        )\n",
    "\n",
    "    elif dist == \"skewed\":\n",
    "        # I want to try something else ,, \n",
    "        # g = torch.Generator(device=device)\n",
    "        # g.manual_seed(seed + 999)\n",
    "        # v = torch.randn(d, generator=g, device=device, dtype=dtype)\n",
    "        # v = v / torch.linalg.norm(v).clamp_min(1e-12)\n",
    "        # X = sample_skewed(\n",
    "        #     n, d, mu_true, Sigma_true,\n",
    "        #     skew_dir=v, skew_scale=skew_scale,\n",
    "        #     device=device, dtype=dtype, seed=seed\n",
    "        # )\n",
    "        X = sample_banana(\n",
    "            n, d, mu_true, Sigma_true,\n",
    "            device=device, dtype=dtype, seed=seed, b=0.2)\n",
    "    else:\n",
    "        raise ValueError(dist)\n",
    "\n",
    "    return X, mu_true, Sigma_true\n",
    "\n",
    "\n",
    "\n",
    "# run the simulation\n",
    "def run_simulation(\n",
    "    R_max_grid=[50],\n",
    "    dist_grid=(\"gaussian\", \"contam_gaussian\", \"t3\", \"skewed\"),\n",
    "    reps=20,\n",
    "    dtype=torch.float32,\n",
    "    seed0=1234,\n",
    "    n_grid=[1000],\n",
    "    d_grid=[10],\n",
    "    rho_grid=[0.1],\n",
    "    # generator params\n",
    "    eta=0.1, shift_scale=2.0, inflate=3.0, skew_scale=4.0,\n",
    "):\n",
    "    device = _device()\n",
    "    print(f\"Running on {device}\")\n",
    "\n",
    "    rows = []\n",
    "    # sqd = torch.sqrt(torch.tensor(float(d), device=device, dtype=dtype))\n",
    "    # R_max_grid=(2*math.sqrt(10), 5*math.sqrt(10), 10*math.sqrt(10)),\n",
    "    # beta_grid=(1.001, 1.01, 1.1),\n",
    "    # tau_grid=(0.8,0.9,0.99),\n",
    "    # tau_schedule_grid=(\"constant\", \"increasing\", \"decreasing\"),\n",
    "    # iters_grid=(1, 2, 3, 4, 5),\n",
    "    n_iter=3\n",
    "    tau=0.9\n",
    "    tau_r=tau-0.3\n",
    "    tau_seq_i = (tau-0.2,tau-0.1,tau)\n",
    "    tau_seq_d = (tau,tau-0.1,tau-0.2) \n",
    "    tau_seq_c = (tau,tau,tau)\n",
    "    tau_seq_i_r = (tau_r-0.2,tau_r-0.1,tau_r)\n",
    "    tau_seq_d_r = (tau_r,tau_r-0.1,tau_r-0.2) \n",
    "    tau_seq_c_r = (tau_r,tau_r,tau_r)\n",
    "\n",
    "    for R_maxx in R_max_grid:\n",
    "        for n in n_grid:\n",
    "            for d in d_grid:\n",
    "                R_max = R_maxx * math.sqrt(d)\n",
    "                for rho in rho_grid:\n",
    "                    for dist in dist_grid:\n",
    "                        for rep in range(reps):\n",
    "                            rho_tag = int(round(1e6 * float(rho)))\n",
    "                            seed = _setting_seed(seed0, rep, n, d, rho, dist=dist, R_max=R_max)\n",
    "\n",
    "                            X, mu_true, Sigma_true = generate_data(\n",
    "                                        dist, n, d, device, dtype, seed,\n",
    "                                        eta, shift_scale, inflate, skew_scale\n",
    "                                    )\n",
    "\n",
    "                            init = torch.zeros(d, device=device, dtype=dtype)\n",
    "\n",
    "                                    # ---- Sample mean (non-private baseline; rho irrelevant)\n",
    "                            mu_mean = X.mean(dim=0)\n",
    "                            err_mean = maha_error(mu_mean, mu_true, Sigma_true)\n",
    "\n",
    "                            # ---- Private ellipse non rob incr\n",
    "                            try:\n",
    "                                mu_ell = em.private_ellipse_iteration(\n",
    "                                            X,\n",
    "                                            rho_total=float(rho),\n",
    "                                            r=R_max,\n",
    "                                            iters=3,\n",
    "                                            init=init,\n",
    "                                            R_min=1.0,\n",
    "                                            R_max=R_max,\n",
    "                                            thresholds=tau_seq_i,\n",
    "                                            beta=1.01,\n",
    "                                            Sigma_unknown= False,\n",
    "                                            Sigma = Sigma_true,\n",
    "                                            max_iter=100000,\n",
    "                                        )\n",
    "                                err_ell_inc = maha_error(mu_ell, mu_true, Sigma_true)\n",
    "                            except Exception:\n",
    "                                err_ell_inc = float(\"nan\")\n",
    "\n",
    "\n",
    "                            # ---- Private ellipse non rob c\n",
    "                            try:\n",
    "                                mu_ell = em.private_ellipse_iteration(\n",
    "                                            X,\n",
    "                                            rho_total=float(rho),\n",
    "                                            r=R_max,\n",
    "                                            iters=3,\n",
    "                                            init=init,\n",
    "                                            R_min=1.0,\n",
    "                                            R_max=R_max,\n",
    "                                            thresholds=tau_seq_c,\n",
    "                                            beta=1.01,\n",
    "                                            Sigma_unknown= False,\n",
    "                                            Sigma = Sigma_true,\n",
    "                                            max_iter=100000,\n",
    "                                        )\n",
    "                                err_ell_c = maha_error(mu_ell, mu_true, Sigma_true)\n",
    "                            except Exception:\n",
    "                                err_ell_c = float(\"nan\")\n",
    "                            # ---- Private ellipse non rob d\n",
    "                            try:\n",
    "                                mu_ell = em.private_ellipse_iteration(\n",
    "                                            X,\n",
    "                                            rho_total=float(rho),\n",
    "                                            r=R_max,\n",
    "                                            iters=3,\n",
    "                                            init=init,\n",
    "                                            R_min=1.0,\n",
    "                                            R_max=R_max,\n",
    "                                            thresholds=tau_seq_d,\n",
    "                                            beta=1.01,\n",
    "                                            Sigma_unknown= False,\n",
    "                                            Sigma = Sigma_true,\n",
    "                                            max_iter=100000,\n",
    "                                        )\n",
    "                                err_ell_d = maha_error(mu_ell, mu_true, Sigma_true)\n",
    "                            except Exception:\n",
    "                                err_ell_d = float(\"nan\")\n",
    "                            # ---- Private ellipse  rob incr\n",
    "                            try:\n",
    "                                mu_ell = em.private_ellipse_iteration(\n",
    "                                            X,\n",
    "                                            rho_total=float(rho),\n",
    "                                            r=R_max,\n",
    "                                            iters=3,\n",
    "                                            init=init,\n",
    "                                            R_min=1.0,\n",
    "                                            R_max=R_max,\n",
    "                                            thresholds=tau_seq_i_r,\n",
    "                                            beta=1.01,\n",
    "                                            Sigma_unknown= False,\n",
    "                                            Sigma = Sigma_true,\n",
    "                                            max_iter=100000,\n",
    "                                        )\n",
    "                                err_ell_inc_r = maha_error(mu_ell, mu_true, Sigma_true)\n",
    "                            except Exception:\n",
    "                                err_ell_inc_r = float(\"nan\")\n",
    "\n",
    "\n",
    "                            # ---- Private ellipse  rob c\n",
    "                            try:\n",
    "                                mu_ell = em.private_ellipse_iteration(\n",
    "                                            X,\n",
    "                                            rho_total=float(rho),\n",
    "                                            r=R_max,\n",
    "                                            iters=3,\n",
    "                                            init=init,\n",
    "                                            R_min=1.0,\n",
    "                                            R_max=R_max,\n",
    "                                            thresholds=tau_seq_c_r,\n",
    "                                            beta=1.01,\n",
    "                                            Sigma_unknown= False,\n",
    "                                            Sigma = Sigma_true,\n",
    "                                            max_iter=100000,\n",
    "                                        )\n",
    "                                err_ell_c_r = maha_error(mu_ell, mu_true, Sigma_true)\n",
    "                            except Exception:\n",
    "                                err_ell_c_r = float(\"nan\")\n",
    "                            # ---- Private ellipse non rob d\n",
    "                            try:\n",
    "                                mu_ell = em.private_ellipse_iteration(\n",
    "                                            X,\n",
    "                                            rho_total=float(rho),\n",
    "                                            r=R_max,\n",
    "                                            iters=3,\n",
    "                                            init=init,\n",
    "                                            R_min=1.0,\n",
    "                                            R_max=R_max,\n",
    "                                            thresholds=tau_seq_d_r,\n",
    "                                            beta=1.01,\n",
    "                                            Sigma_unknown= False,\n",
    "                                            Sigma = Sigma_true,\n",
    "                                            max_iter=100000,\n",
    "                                        )\n",
    "                                err_ell_d_r = maha_error(mu_ell, mu_true, Sigma_true)\n",
    "                            except Exception:\n",
    "                                err_ell_d_r = float(\"nan\")\n",
    "                            rows.append({\n",
    "                                        \"dist\": dist,\n",
    "                                        \"n\": int(n),\n",
    "                                        \"d\": int(d),\n",
    "                                        \"rep\": int(rep),\n",
    "                                        \"rho\": float(rho),\n",
    "                                        # \"mh_mean\": float(err_mean),                       \n",
    "                                        \"mh_ellipse_inc\": float(err_ell_inc),\n",
    "                                        \"mh_ellipse_c\": float(err_ell_c),\n",
    "                                        \"mh_ellipse_d\": float(err_ell_d),\n",
    "                                        \"mh_ellipse_inc_r\": float(err_ell_inc_r),\n",
    "                                        \"mh_ellipse_c_r\": float(err_ell_c_r),\n",
    "                                        \"mh_ellipse_d_r\": float(err_ell_d_r),\n",
    "                                        \"beta\": float(1.01),\n",
    "                                        \"iters\": int(3),\n",
    "                                        \"eta\": float(eta),\n",
    "                                        \"R_max\": float(R_max)\n",
    "                                    })\n",
    "\n",
    "            #\n",
    "    out_path=\"mh_errors_different_tau_schedule.csv\"\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"Saved {len(df)} rows to {out_path}\")\n",
    "    # now save the df to a file, and go to next parameter \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44351d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Example\n",
    "# -----------------------------\n",
    "d_grid = [5, 20, 50, 100]\n",
    "n_grid = [500,  2000]\n",
    "rho_grid= [0.1,1]\n",
    "df_list = run_simulation(n_grid=n_grid,d_grid=d_grid,rho_grid=rho_grid,  reps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data and make the plots\n",
    "df=pd.read_csv(\"mh_errors_different_tau_schedule.csv\")\n",
    "df.head()\n",
    "df= df.rename(columns={\"rho\": \"ρ\"})\n",
    "\n",
    "dist_map = {\n",
    "    \"gaussian\": \"Gaussian\",\n",
    "    \"contam_gaussian\": \"Contam. Gaussian\",\n",
    "    \"skewed\": \"Banana-shaped\",\n",
    "    \"t3\": r\"$t_3$\"\n",
    "}\n",
    "\n",
    "df[\"dist\"] = df[\"dist\"].replace(dist_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eacb3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a50e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def is_robust(name: str) -> bool:\n",
    "    return \"low-$\\\\tau$\" in name.lower()\n",
    "\n",
    "def tau_type(name: str) -> str:\n",
    "    s = name.lower()\n",
    "    if \"increasing\" in s: return \"inc\"\n",
    "    if \"constant\" in s:   return \"const\"\n",
    "    if \"decreasing\" in s: return \"dec\"\n",
    "    return \"other\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa61771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_mh_boxplots_by_n_split(\n",
    "    df,\n",
    "    robust=False,                 # False: non-robust (no _r). True: robust (endswith _r)\n",
    "    facet_by=(\"d\",),\n",
    "    x=\"n\",\n",
    "    id_cols=(\"dist\", \"n\", \"d\", \"rep\", \"ρ\"),\n",
    "    mh_prefix=\"mh_\",\n",
    "    height=3.6,\n",
    "    aspect=1.15,\n",
    "    col_wrap=3,\n",
    "    outpath=None,\n",
    "    show=True,\n",
    "    title_suffix=True,\n",
    "    rho=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Boxplots of error for differing schedules\n",
    "    \"\"\"\n",
    "    df=df[df['ρ']==rho]\n",
    "    # find mh columns automatically\n",
    "    mh_cols_all = [c for c in df.columns if c.startswith(mh_prefix)]\n",
    "    if len(mh_cols_all) == 0:\n",
    "        raise ValueError(f\"No columns starting with '{mh_prefix}' found.\")\n",
    "\n",
    "    if robust:\n",
    "        mh_cols = [c for c in mh_cols_all if c.endswith(\"_r\")]\n",
    "        which = \"Robust (low $\\\\tau$)\"\n",
    "    else:\n",
    "        mh_cols = [c for c in mh_cols_all if not c.endswith(\"_r\")]\n",
    "        which = \"Non-robust (high $\\\\tau$)\"\n",
    "\n",
    "    if len(mh_cols) == 0:\n",
    "        raise ValueError(\n",
    "            f\"No columns found for robust={robust}. \"\n",
    "            f\"(Expected suffix '_r' if robust=True.)\"\n",
    "        )\n",
    "\n",
    "    # rename map \n",
    "    rename_map = {\n",
    "        \"mh_ellipse_inc\":   \"Increasing $\\\\tau$\",\n",
    "        \"mh_ellipse_c\":     \"Constant $\\\\tau$\",\n",
    "        \"mh_ellipse_d\":     \"Decreasing $\\\\tau$\",\n",
    "        \"mh_ellipse_inc_r\": \"Increasing $\\\\tau$\",\n",
    "        \"mh_ellipse_c_r\":   \"Constant $\\\\tau$\",\n",
    "        \"mh_ellipse_d_r\":   \"Decreasing $\\\\tau$\",\n",
    "    }\n",
    "\n",
    "    def _fallback_name(col: str) -> str:\n",
    "        s = col.replace(\"mh_\", \"\")\n",
    "        s = s.replace(\"_r\", \"\")  # strip robust suffix for labeling\n",
    "        s = s.replace(\"_\", \" \").strip()\n",
    "        return s.title()\n",
    "\n",
    "    #  melt to long \n",
    "    long = df[list(id_cols) + mh_cols].melt(\n",
    "        id_vars=list(id_cols),\n",
    "        value_vars=mh_cols,\n",
    "        var_name=\"method\",\n",
    "        value_name=\"error\"\n",
    "    )\n",
    "\n",
    "    long[\"method\"] = (\n",
    "        long[\"method\"]\n",
    "        .astype(str)\n",
    "        .map(lambda m: rename_map.get(m, _fallback_name(m)))\n",
    "        .str.strip()\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    )\n",
    "\n",
    "    # Treat x as categorical\n",
    "    if x in long.columns:\n",
    "        long[x] = long[x].astype(str)\n",
    "\n",
    "    # force method order: inc, const, dec \n",
    "    hue_order = [\"Increasing $\\\\tau$\", \"Constant $\\\\tau$\", \"Decreasing $\\\\tau$\"]\n",
    "    hue_order = [h for h in hue_order if h in long[\"method\"].unique()]\n",
    "    long[\"method\"] = pd.Categorical(long[\"method\"], categories=hue_order, ordered=True)\n",
    "\n",
    "    # --- build facets ---\n",
    "    facet_by = tuple(facet_by)\n",
    "\n",
    "    if len(facet_by) == 1:\n",
    "        g = sns.catplot(\n",
    "            data=long,\n",
    "            kind=\"box\",\n",
    "            x=x, y=\"error\", hue=\"method\",\n",
    "            col=facet_by[0],\n",
    "            col_wrap=col_wrap,\n",
    "            height=height, aspect=aspect,\n",
    "            sharey=False,\n",
    "            hue_order=hue_order\n",
    "        )\n",
    "    elif len(facet_by) == 2:\n",
    "        g = sns.catplot(\n",
    "            data=long,\n",
    "            kind=\"box\",\n",
    "            x=x, y=\"error\", hue=\"method\",\n",
    "            col=facet_by[0], row=facet_by[1],\n",
    "            height=height, aspect=aspect,\n",
    "            sharey=False,\n",
    "            hue_order=hue_order\n",
    "        )\n",
    "    else:\n",
    "        g = sns.catplot(\n",
    "            data=long,\n",
    "            kind=\"box\",\n",
    "            x=x, y=\"error\", hue=\"method\",\n",
    "            col=facet_by[0], row=facet_by[1],\n",
    "            height=height, aspect=aspect,\n",
    "            sharey=False,\n",
    "            hue_order=hue_order\n",
    "        )\n",
    "\n",
    "    g.set_axis_labels(x, \"\")\n",
    "    g.set_titles(row_template=\"{row_name}\", col_template=\"d = {col_name}\")\n",
    "\n",
    "    # Put y-label\n",
    "    try:\n",
    "        for ax in g.axes[:, -1]:\n",
    "            ax.set_ylabel(\"Logged Mahalanobis error\")\n",
    "            ax.yaxis.set_label_position(\"left\")\n",
    "            ax.yaxis.tick_left()\n",
    "    except Exception:\n",
    "        # happens if g.axes isn't a 2D array in some facet layouts\n",
    "        pass\n",
    "\n",
    "    if g._legend is None:\n",
    "        g.add_legend()\n",
    "\n",
    "    # move legend into the first panel (top-right)\n",
    "    ax0 = g.axes.flatten()[0]\n",
    "\n",
    "    # grab handles/labels from the figure-level legend\n",
    "    handles = g._legend.legend_handles\n",
    "    labels = [t.get_text() for t in g._legend.texts]\n",
    "\n",
    "    # remove the figure-level legend\n",
    "    g._legend.remove()\n",
    "\n",
    "    # add an axes-level legend\n",
    "    ax0.legend(\n",
    "        handles, labels,\n",
    "        loc=\"upper right\",\n",
    "        frameon=True,\n",
    "        title=\"\"   # optional\n",
    "    )\n",
    "\n",
    "\n",
    "    # Rotate ticks if needed\n",
    "    for ax in g.axes.flatten():\n",
    "        ax.tick_params(axis=\"x\", rotation=0)\n",
    "\n",
    "    # Optional overall title\n",
    "    if title_suffix:\n",
    "        g.fig.suptitle(f\"{which} variant, $\\\\rho=$\"+str(rho), y=1.02, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if outpath is not None:\n",
    "        plt.savefig(outpath, dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(g.fig)\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c567577",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mh_boxplots_by_n_split(df, robust=False, facet_by=(\"dist\",\"d\"),rho=0.1,col_wrap=4,outpath=\"tau_schedule_nonrobust_small_rho.png\")\n",
    "plot_mh_boxplots_by_n_split(df, robust=False, facet_by=(\"dist\",\"d\"),rho=1, col_wrap=4,outpath=\"tau_schedule_nonrobust_large_rho.png\")\n",
    "plot_mh_boxplots_by_n_split(df, robust=True, facet_by=(\"dist\",\"d\"),rho=0.1, col_wrap=4,outpath=\"tau_schedule_robust_small_rho.png\")\n",
    "plot_mh_boxplots_by_n_split(df, robust=True, facet_by=(\"dist\",\"d\"),rho=1, col_wrap=4,outpath=\"tau_schedule_robust_large_rho.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d6978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
